{"name":"深度学习","slug":"深度学习","count":1,"postlist":[{"title":"训练深度学习网络的挑战和解决方法","uid":"a71e8b888458c8851815d0b96809bb00","slug":"训练深度学习网络的挑战和解决方法","date":"2019-12-27T09:46:48.000Z","updated":"2021-08-19T06:00:23.757Z","comments":true,"path":"api/articles/训练深度学习网络的挑战和解决方法.json","keywords":null,"cover":"https://image-assets.mihuashi.com/2021/08/15/09/FixrUuTczBtvQo8U9j-X2eCGMrzm.png","text":"Hands-on ml2 Ch.11 读书笔记。 Vanishing/Exploding Gradients在深度学习网络训练过程中，更深层次的网络梯度下降幅度越小，导致深层次的网络权重保持不变。或一些层梯度过大，每次权值更新的幅度很大（如 RNN）。导致不同层的学习速度相差较大...","link":"","photos":[],"count_time":{"symbolsCount":"1.8k","symbolsTime":"2 mins."},"categories":[{"name":"笔记","slug":"笔记","count":3,"path":"api/categories/笔记.json"}],"tags":[{"name":"读书笔记","slug":"读书笔记","count":3,"path":"api/tags/读书笔记.json"},{"name":"深度学习","slug":"深度学习","count":1,"path":"api/tags/深度学习.json"}],"author":{"name":"Ryanhui","slug":"blog-author","avatar":"https://avatars1.githubusercontent.com/u/43368274?s=460&u=50a78f666213a52518d0076c1ca1cd9862076167&v=4","link":"/","description":"写博客，不过是孤芳自赏","socials":{"github":"https://weibo.com/wbgjh","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://github.com/Ranhuiryan","zhihu":"","csdn":"","juejin":"","customs":{}}}}]}